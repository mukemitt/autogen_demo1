{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– AutoGen Advanced Multi-Agent Collaboration Demo (Google Colab Version)\n",
    "\n",
    "## Concept: Specialized Agent Roles with Dynamic Tool Integration\n",
    "\n",
    "This notebook demonstrates an advanced AutoGen concept: **Creating specialized agents with distinct roles that can dynamically collaborate and utilize external tools**.\n",
    "\n",
    "### ðŸ“Œ Important: Google Colab Setup Required\n",
    "This notebook is optimized for Google Colab. It includes:\n",
    "- Automatic package installation\n",
    "- Secure API key handling via Google Colab secrets\n",
    "- Colab-specific configurations\n",
    "\n",
    "### Key Discussion Points:\n",
    "1. **Agent Specialization**: How different agents can have unique expertise\n",
    "2. **Dynamic Collaboration**: Agents deciding when to collaborate vs. work independently\n",
    "3. **Tool Integration**: Agents using external tools and sharing results\n",
    "4. **Conversation Flow Control**: Managing complex multi-agent interactions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Scenario: Data Science Team Simulation\n",
    "\n",
    "We'll create a virtual data science team with three specialized agents:\n",
    "- **Data Analyst**: Focuses on data exploration and statistical analysis\n",
    "- **ML Engineer**: Handles model development and evaluation\n",
    "- **Product Manager**: Makes strategic decisions and prioritizes tasks\n",
    "\n",
    "### Why This Matters:\n",
    "- **Real-world Application**: Mirrors actual team dynamics\n",
    "- **Scalable Pattern**: Can be extended to any domain\n",
    "- **Efficiency**: Each agent contributes their specialized knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Installing required packages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pyautogen==0.2.25 (from versions: 0.0.1, 0.1.0, 0.1.1rc1, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.1.10, 0.1.11, 0.1.12, 0.1.13, 0.1.14, 0.2.0b1, 0.2.0b2, 0.4b1, 0.4, 0.4.1, 0.4.2b1, 0.5.0b2, 0.5.0, 0.5.1, 0.5.2b1, 0.5.2, 0.5.3b1, 0.5.3, 0.6.0b1, 0.6.0b2, 0.6.0, 0.6.1, 0.7.0b1, 0.7.0b2, 0.7.0b3, 0.7.0, 0.7.1, 0.7.2b1, 0.7.2, 0.7.3, 0.7.4b1, 0.7.4b2, 0.7.4, 0.7.5, 0.7.6b1, 0.7.6, 0.8.0b1, 0.8.0, 0.8.1, 0.8.2rc0, 0.8.2, 0.8.3, 0.8.4, 0.8.5a0, 0.8.5a1, 0.8.5, 0.8.6a2, 0.8.6b0, 0.8.6, 0.8.7, 0.8.8a0, 0.8.8a1, 0.9a0, 0.9a1, 0.9.0a2, 0.9.0a3, 0.9, 0.9.1a1, 0.10.0)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for pyautogen==0.2.25\n",
      "The system cannot find the file specified.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages installed successfully!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Packages installed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Import AutoGen and other libraries\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'autogen'"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Package Installation and Setup (Google Colab)\n",
    "print(\"ðŸ”„ Installing required packages...\")\n",
    "\n",
    "# Install AutoGen and dependencies\n",
    "!pip install -q pyautogen==0.2.25\n",
    "!pip install -q openai>=1.3,<2.0\n",
    "!pip install -q pandas matplotlib seaborn\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Packages installed successfully!\")\n",
    "\n",
    "# Import AutoGen and other libraries\n",
    "import autogen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "\n",
    "print(f\"ðŸ“¦ AutoGen version: {autogen.__version__}\")\n",
    "\n",
    "# Google Colab secrets setup\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"ðŸ”‘ API key loaded from Google Colab secrets\")\n",
    "except ImportError:\n",
    "    # Fallback for non-Colab environments\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY:\n",
    "        print(\"âš ï¸ Warning: No API key found. Please set up your OpenAI API key.\")\n",
    "        OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
    "    print(\"ðŸ”‘ API key loaded from environment/input\")\n",
    "\n",
    "# Configuration\n",
    "config_list = [{\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": OPENAI_API_KEY,\n",
    "}]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.7,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "print(\"ðŸŽ¯ Configuration complete!\")\n",
    "print(\"ðŸš€ Ready to create AutoGen agents!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import autogen\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "config_list = [{\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "}]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.7,\n",
    "    \"timeout\": 120,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analyst Agent - Specialized in data exploration\n",
    "data_analyst = autogen.AssistantAgent(\n",
    "    name=\"DataAnalyst\",\n",
    "    system_message=\"\"\"You are a Senior Data Analyst with expertise in:\n",
    "    - Exploratory Data Analysis (EDA)\n",
    "    - Statistical analysis and hypothesis testing\n",
    "    - Data visualization and storytelling\n",
    "    - Data quality assessment\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Always start with understanding the data structure\n",
    "    2. Look for patterns, outliers, and data quality issues\n",
    "    3. Create meaningful visualizations\n",
    "    4. Collaborate with ML Engineer for feature insights\n",
    "    5. Present findings clearly to Product Manager\n",
    "    \n",
    "    Use code execution for data analysis tasks.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"/content/data_analysis\",  # Colab-friendly path\n",
    "        \"use_docker\": False  # Docker not available in Colab\n",
    "    }\n",
    ")\n",
    "\n",
    "# ML Engineer Agent - Specialized in model development\n",
    "ml_engineer = autogen.AssistantAgent(\n",
    "    name=\"MLEngineer\",\n",
    "    system_message=\"\"\"You are a Senior ML Engineer with expertise in:\n",
    "    - Machine learning model development and evaluation\n",
    "    - Feature engineering and selection\n",
    "    - Model performance optimization\n",
    "    - MLOps and deployment considerations\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Build on insights from Data Analyst\n",
    "    2. Focus on model performance and generalization\n",
    "    3. Consider computational efficiency and scalability\n",
    "    4. Validate findings with proper cross-validation\n",
    "    5. Communicate technical results to non-technical stakeholders\n",
    "    \n",
    "    Use code execution for model development and evaluation.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"/content/ml_development\",  # Colab-friendly path\n",
    "        \"use_docker\": False  # Docker not available in Colab\n",
    "    }\n",
    ")\n",
    "\n",
    "# Product Manager Agent - Specialized in strategic decisions\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"ProductManager\",\n",
    "    system_message=\"\"\"You are a Senior Product Manager with expertise in:\n",
    "    - Strategic planning and prioritization\n",
    "    - Business impact assessment\n",
    "    - Stakeholder communication\n",
    "    - Resource allocation and timeline management\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Focus on business value and user impact\n",
    "    2. Ask clarifying questions about requirements\n",
    "    3. Prioritize tasks based on effort vs. impact\n",
    "    4. Synthesize technical findings into business insights\n",
    "    5. Make final decisions on project direction\n",
    "    \n",
    "    You don't execute code but guide the technical team's efforts.\"\"\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"ðŸ‘¥ Specialized agents created successfully!\")\n",
    "print(f\"ðŸ“Š Data Analyst: {data_analyst.name}\")\n",
    "print(f\"ðŸ¤– ML Engineer: {ml_engineer.name}\")\n",
    "print(f\"ðŸ“‹ Product Manager: {product_manager.name}\")\n",
    "print(\"ðŸŽ¯ All agents configured for Google Colab environment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analyst Agent - Specialized in data exploration\n",
    "data_analyst = autogen.AssistantAgent(\n",
    "    name=\"DataAnalyst\",\n",
    "    system_message=\"\"\"You are a Senior Data Analyst with expertise in:\n",
    "    - Exploratory Data Analysis (EDA)\n",
    "    - Statistical analysis and hypothesis testing\n",
    "    - Data visualization and storytelling\n",
    "    - Data quality assessment\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Always start with understanding the data structure\n",
    "    2. Look for patterns, outliers, and data quality issues\n",
    "    3. Create meaningful visualizations\n",
    "    4. Collaborate with ML Engineer for feature insights\n",
    "    5. Present findings clearly to Product Manager\n",
    "    \n",
    "    Use code execution for data analysis tasks.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"data_analysis\",\n",
    "        \"use_docker\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "# ML Engineer Agent - Specialized in model development\n",
    "ml_engineer = autogen.AssistantAgent(\n",
    "    name=\"MLEngineer\",\n",
    "    system_message=\"\"\"You are a Senior ML Engineer with expertise in:\n",
    "    - Machine learning model development and evaluation\n",
    "    - Feature engineering and selection\n",
    "    - Model performance optimization\n",
    "    - MLOps and deployment considerations\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Build on insights from Data Analyst\n",
    "    2. Focus on model performance and generalization\n",
    "    3. Consider computational efficiency and scalability\n",
    "    4. Validate findings with proper cross-validation\n",
    "    5. Communicate technical results to non-technical stakeholders\n",
    "    \n",
    "    Use code execution for model development and evaluation.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"ml_development\",\n",
    "        \"use_docker\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "# Product Manager Agent - Specialized in strategic decisions\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"ProductManager\",\n",
    "    system_message=\"\"\"You are a Senior Product Manager with expertise in:\n",
    "    - Strategic planning and prioritization\n",
    "    - Business impact assessment\n",
    "    - Stakeholder communication\n",
    "    - Resource allocation and timeline management\n",
    "    \n",
    "    When working on tasks:\n",
    "    1. Focus on business value and user impact\n",
    "    2. Ask clarifying questions about requirements\n",
    "    3. Prioritize tasks based on effort vs. impact\n",
    "    4. Synthesize technical findings into business insights\n",
    "    5. Make final decisions on project direction\n",
    "    \n",
    "    You don't execute code but guide the technical team's efforts.\"\"\",\n",
    "    llm_config=llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ­ Advanced Group Chat with Custom Speaker Selection\n",
    "\n",
    "### Discussion Point: Intelligent conversation flow\n",
    "\n",
    "Instead of simple round-robin, we'll implement a custom speaker selection that:\n",
    "- Considers the current task context\n",
    "- Allows natural handoffs between agents\n",
    "- Prevents unnecessary back-and-forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom speaker selection function\n",
    "def custom_speaker_selection(last_speaker, groupchat):\n",
    "    \"\"\"Intelligent speaker selection based on conversation context\"\"\"\n",
    "    \n",
    "    # Get the last few messages to understand context\n",
    "    recent_messages = groupchat.messages[-3:] if len(groupchat.messages) >= 3 else groupchat.messages\n",
    "    last_message = groupchat.messages[-1]['content'].lower() if groupchat.messages else \"\"\n",
    "    \n",
    "    # Keywords that suggest which agent should speak next\n",
    "    data_keywords = ['data', 'analysis', 'visualization', 'explore', 'statistics']\n",
    "    ml_keywords = ['model', 'prediction', 'algorithm', 'feature', 'accuracy', 'training']\n",
    "    pm_keywords = ['business', 'priority', 'decision', 'requirements', 'timeline', 'impact']\n",
    "    \n",
    "    # Determine next speaker based on context\n",
    "    if any(keyword in last_message for keyword in data_keywords):\n",
    "        return data_analyst\n",
    "    elif any(keyword in last_message for keyword in ml_keywords):\n",
    "        return ml_engineer\n",
    "    elif any(keyword in last_message for keyword in pm_keywords):\n",
    "        return product_manager\n",
    "    \n",
    "    # Default rotation if no clear context\n",
    "    agents = [data_analyst, ml_engineer, product_manager]\n",
    "    try:\n",
    "        current_index = agents.index(last_speaker)\n",
    "        return agents[(current_index + 1) % len(agents)]\n",
    "    except ValueError:\n",
    "        return data_analyst  # Default to data analyst\n",
    "\n",
    "# Create the group chat with custom selection\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[data_analyst, ml_engineer, product_manager],\n",
    "    messages=[],\n",
    "    max_round=15,\n",
    "    speaker_selection_method=custom_speaker_selection,\n",
    "    allow_repeat_speaker=False\n",
    ")\n",
    "\n",
    "# Group chat manager\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are managing a data science team conversation. \n",
    "    Ensure each agent contributes their expertise and that the conversation \n",
    "    stays focused on the task at hand. Facilitate smooth handoffs between agents.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Demo: Customer Churn Analysis Project\n",
    "\n",
    "### Discussion Point: Real-world collaboration patterns\n",
    "\n",
    "Watch how each agent:\n",
    "- Contributes unique expertise\n",
    "- Builds on others' work\n",
    "- Makes decisions within their domain\n",
    "- Collaborates naturally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user proxy to initiate the conversation\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    system_message=\"You represent the business stakeholder requesting the analysis.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "# Start the collaboration\n",
    "initial_task = \"\"\"\n",
    "We need to build a customer churn prediction model for our subscription service.\n",
    "\n",
    "Context:\n",
    "- We have historical customer data including demographics, usage patterns, and churn status\n",
    "- Business goal: Reduce churn by 15% in the next quarter\n",
    "- We need actionable insights for the customer success team\n",
    "\n",
    "Requirements:\n",
    "1. Analyze the current churn patterns\n",
    "2. Build a predictive model\n",
    "3. Identify key factors that drive churn\n",
    "4. Provide recommendations for intervention strategies\n",
    "\n",
    "Please work together to develop a comprehensive solution.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== AutoGen Advanced Multi-Agent Demo: Customer Churn Analysis ===\")\n",
    "print(\"Watch how specialized agents collaborate on a complex data science project...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the multi-agent conversation\n",
    "# Note: This will start an interactive conversation between the agents\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=initial_task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Conversation Analysis\n",
    "\n",
    "### Discussion Points for Review:\n",
    "\n",
    "1. **Agent Specialization**: \n",
    "   - How did each agent contribute their unique expertise?\n",
    "   - Were there clear boundaries between roles?\n",
    "\n",
    "2. **Collaboration Patterns**:\n",
    "   - How did agents build on each other's work?\n",
    "   - Were there natural handoffs between agents?\n",
    "\n",
    "3. **Decision Making**:\n",
    "   - How were technical vs. business decisions handled?\n",
    "   - Was there a clear decision-making hierarchy?\n",
    "\n",
    "4. **Tool Usage**:\n",
    "   - How effectively did agents use code execution?\n",
    "   - Were results shared and built upon by other agents?\n",
    "\n",
    "5. **Communication Quality**:\n",
    "   - Was technical information translated for business stakeholders?\n",
    "   - Were action items and next steps clear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze the conversation\n",
    "def analyze_conversation(chat_result):\n",
    "    \"\"\"Analyze the multi-agent conversation patterns\"\"\"\n",
    "    \n",
    "    if hasattr(chat_result, 'chat_history'):\n",
    "        messages = chat_result.chat_history\n",
    "    else:\n",
    "        messages = groupchat.messages\n",
    "    \n",
    "    # Count contributions by each agent\n",
    "    agent_contributions = {}\n",
    "    for msg in messages:\n",
    "        speaker = msg.get('name', 'Unknown')\n",
    "        agent_contributions[speaker] = agent_contributions.get(speaker, 0) + 1\n",
    "    \n",
    "    print(\"ðŸ“ˆ Conversation Statistics:\")\n",
    "    print(f\"Total messages: {len(messages)}\")\n",
    "    print(\"\\nContributions by agent:\")\n",
    "    for agent, count in agent_contributions.items():\n",
    "        print(f\"  {agent}: {count} messages\")\n",
    "    \n",
    "    # Analyze conversation flow\n",
    "    print(\"\\nðŸ”„ Conversation Flow:\")\n",
    "    speaker_sequence = [msg.get('name', 'Unknown') for msg in messages[-10:]]  # Last 10 messages\n",
    "    print(f\"Recent speakers: {' â†’ '.join(speaker_sequence)}\")\n",
    "    \n",
    "    return agent_contributions\n",
    "\n",
    "# Analyze the conversation\n",
    "conversation_stats = analyze_conversation(chat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Key Takeaways and Extensions\n",
    "\n",
    "### What We Demonstrated:\n",
    "1. **Specialized Agent Roles**: Each agent has distinct expertise and responsibilities\n",
    "2. **Intelligent Speaker Selection**: Context-aware conversation flow\n",
    "3. **Tool Integration**: Agents using code execution for their specialized tasks\n",
    "4. **Natural Collaboration**: Agents building on each other's work\n",
    "\n",
    "### Potential Extensions:\n",
    "1. **Dynamic Team Composition**: Add/remove agents based on task requirements\n",
    "2. **External Tool Integration**: Connect to databases, APIs, cloud services\n",
    "3. **Memory and State Management**: Agents remembering past conversations\n",
    "4. **Human-in-the-Loop**: Strategic points for human intervention\n",
    "5. **Multi-Modal Capabilities**: Agents working with images, documents, etc.\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Software Development Teams**: Developer, QA, Product Owner agents\n",
    "- **Research Teams**: Researcher, Reviewer, Editor agents\n",
    "- **Business Analysis**: Analyst, Strategist, Implementation agents\n",
    "- **Customer Support**: Technical, Billing, Escalation agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Google Colab Tips & Troubleshooting\n",
    "\n",
    "### ðŸ”§ Common Issues and Solutions:\n",
    "\n",
    "1. **Package Installation Issues**:\n",
    "   ```python\n",
    "   # If packages fail to install, try:\n",
    "   !pip install --upgrade pip\n",
    "   !pip install pyautogen --force-reinstall\n",
    "   ```\n",
    "\n",
    "2. **API Key Issues**:\n",
    "   ```python\n",
    "   # Test your API key:\n",
    "   print(f\"API Key loaded: {'Yes' if OPENAI_API_KEY else 'No'}\")\n",
    "   print(f\"Key starts with: {OPENAI_API_KEY[:8] if OPENAI_API_KEY else 'None'}...\")\n",
    "   ```\n",
    "\n",
    "3. **File Path Issues**:\n",
    "   ```python\n",
    "   # Check available directories:\n",
    "   import os\n",
    "   print(\"Current directory:\", os.getcwd())\n",
    "   print(\"Available directories:\", os.listdir('/content'))\n",
    "   ```\n",
    "\n",
    "4. **Memory Issues**:\n",
    "   - Use `Runtime > Factory reset runtime` if you encounter memory issues\n",
    "   - Consider using shorter conversations or fewer agents for complex tasks\n",
    "\n",
    "### ðŸš€ Performance Tips:\n",
    "- Run cells in order to ensure proper setup\n",
    "- Use `Runtime > Run all` to execute the entire notebook\n",
    "- Save important results as they may be lost when the runtime disconnects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Try It Yourself!\n",
    "\n",
    "### Experiment Ideas:\n",
    "\n",
    "1. **Modify Agent Personalities**:\n",
    "   ```python\n",
    "   # Try different system messages to change agent behavior\n",
    "   # Make one agent more conservative, another more innovative\n",
    "   ```\n",
    "\n",
    "2. **Add New Agents**:\n",
    "   ```python\n",
    "   # Add a QA Engineer agent\n",
    "   # Add a DevOps Engineer agent\n",
    "   # Add a Business Analyst agent\n",
    "   ```\n",
    "\n",
    "3. **Custom Speaker Selection**:\n",
    "   ```python\n",
    "   # Implement time-based speaker selection\n",
    "   # Add expertise-based routing\n",
    "   # Create hierarchical decision making\n",
    "   ```\n",
    "\n",
    "4. **Different Scenarios**:\n",
    "   - Software bug investigation\n",
    "   - Market research project\n",
    "   - Process optimization\n",
    "   - Crisis response simulation\n",
    "\n",
    "### Discussion Questions:\n",
    "1. How would you adapt this pattern for your specific use case?\n",
    "2. What safeguards would you add for production use?\n",
    "3. How would you measure the effectiveness of agent collaboration?\n",
    "4. What role should humans play in these multi-agent systems?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
