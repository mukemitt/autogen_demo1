{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– AutoGen Basic Concepts Tutorial\n",
    "\n",
    "## Welcome to AutoGen!\n",
    "\n",
    "This notebook introduces the fundamental concepts of Microsoft AutoGen - a framework for creating multi-agent conversational systems.\n",
    "\n",
    "### What You'll Learn:\n",
    "1. **Core AutoGen Concepts**: Agents, conversations, and configurations\n",
    "2. **Basic Agent Types**: UserProxyAgent and AssistantAgent\n",
    "3. **Simple Conversations**: Two-agent interactions\n",
    "4. **Code Execution**: How agents can run code\n",
    "5. **Group Chats**: Multiple agents working together\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Installation\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AutoGen and dependencies imported successfully!\n",
      "ğŸ“¦ Using autogen-agentchat version 0.6.4\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… AutoGen and dependencies imported successfully!\")\n",
    "print(\"ğŸ“¦ Using autogen-agentchat version 0.6.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration Setup\n",
    "\n",
    "### Key Concept: LLM Configuration\n",
    "\n",
    "AutoGen agents need to know how to connect to language models. We configure this once and reuse it for all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Model client configuration ready!\n",
      "ğŸ¯ Using model: gpt-3.5-turbo\n",
      "ğŸŒ¡ï¸ Temperature and other parameters controlled by model client\n"
     ]
    }
   ],
   "source": [
    "# Configuration for connecting to OpenAI\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-3.5-turbo\",  # You can also use \"gpt-4\" if you have access\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "print(\"ğŸ”‘ Model client configuration ready!\")\n",
    "print(f\"ğŸ¯ Using model: gpt-3.5-turbo\")\n",
    "print(\"ğŸŒ¡ï¸ Temperature and other parameters controlled by model client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤ Basic Concept 1: Two-Agent Conversation\n",
    "\n",
    "### UserProxyAgent vs AssistantAgent\n",
    "\n",
    "- **UserProxyAgent**: Represents the human user, can execute code\n",
    "- **AssistantAgent**: AI assistant that generates responses and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¥ Basic agents created!\n",
      "ğŸ§‘ User Proxy: User\n",
      "ğŸ¤– Assistant: Assistant\n",
      "â„¹ï¸ Note: In the new autogen version, conversations work differently\n"
     ]
    }
   ],
   "source": [
    "# Create an AssistantAgent (AI assistant)\n",
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"\"\"You are a helpful AI assistant. \n",
    "    You can help with coding, analysis, and problem-solving.\n",
    "    When you need to demonstrate code, write Python code examples.\"\"\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "# Create a UserProxyAgent (represents you, the user)\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¥ Basic agents created!\")\n",
    "print(f\"ğŸ§‘ User Proxy: {user_proxy.name}\")\n",
    "print(f\"ğŸ¤– Assistant: {assistant.name}\")\n",
    "print(\"â„¹ï¸ Note: In the new autogen version, conversations work differently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Have Our First Conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Start a simple conversation using the new autogen API\nprint(\"ğŸ—£ï¸ Starting a basic conversation with the assistant...\\n\")\n\nasync def run_simple_demo():\n    # Simple task for demo\n    result = await assistant.run(task=\"Say hello and introduce yourself briefly.\")\n    \n    # Extract just the content from the result for cleaner demo output\n    if hasattr(result, 'messages') and result.messages:\n        last_message = result.messages[-1]\n        if hasattr(last_message, 'content'):\n            return last_message.content\n    return str(result)\n\n# Execute the simple demo\ndemo_result = await run_simple_demo()\nprint(\"Assistant Response:\", demo_result)\nprint(\"\\nâœ… Simple conversation completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Basic Concept 2: Code Execution\n",
    "\n",
    "### How AutoGen Handles Code\n",
    "\n",
    "1. Assistant writes code in markdown code blocks\n",
    "2. UserProxy detects the code and executes it\n",
    "3. Results are shared back with the assistant\n",
    "4. Conversation continues based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Let's try a simple coding demo\nprint(\"ğŸ”¢ Simple coding demonstration...\\n\")\n\nasync def run_simple_coding():\n    task = \"Write a simple Python function to add two numbers. Just show the code, keep it brief.\"\n    \n    result = await assistant.run(task=task)\n    \n    # Extract just the content for cleaner demo output\n    if hasattr(result, 'messages') and result.messages:\n        last_message = result.messages[-1]\n        if hasattr(last_message, 'content'):\n            return last_message.content\n    return str(result)\n\n# Execute the simple coding demo\ncoding_result = await run_simple_coding()\nprint(\"Assistant Response:\", coding_result)\nprint(\"\\nğŸ“Š Simple coding demo completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘¥ Basic Concept 3: Group Chat (Multiple Agents)\n",
    "\n",
    "### Beyond Two Agents\n",
    "\n",
    "Group chats allow multiple agents to collaborate on complex tasks. Each agent can have specialized roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¨â€ğŸ« Specialized agents created:\n",
      "ğŸ“š Teacher: Teacher\n",
      "ğŸ’» Coder: Coder\n",
      "ğŸ” Reviewer: Reviewer\n",
      "â„¹ï¸ Note: Team collaboration works differently in the new version\n"
     ]
    }
   ],
   "source": [
    "# Create specialized agents for a team collaboration\n",
    "\n",
    "# Teacher agent - explains concepts\n",
    "teacher = AssistantAgent(\n",
    "    name=\"Teacher\",\n",
    "    system_message=\"\"\"You are a patient teacher who explains programming concepts clearly.\n",
    "    Focus on education and helping students understand the 'why' behind solutions.\"\"\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "# Coder agent - writes code\n",
    "coder = AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=\"\"\"You are an expert programmer who writes clean, efficient code.\n",
    "    Focus on practical implementation and best practices.\"\"\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "# Reviewer agent - checks and improves code\n",
    "reviewer = AssistantAgent(\n",
    "    name=\"Reviewer\",\n",
    "    system_message=\"\"\"You are a code reviewer who focuses on quality, security, and optimization.\n",
    "    Point out potential issues and suggest improvements.\"\"\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¨â€ğŸ« Specialized agents created:\")\n",
    "print(f\"ğŸ“š Teacher: {teacher.name}\")\n",
    "print(f\"ğŸ’» Coder: {coder.name}\")\n",
    "print(f\"ğŸ” Reviewer: {reviewer.name}\")\n",
    "print(\"â„¹ï¸ Note: Team collaboration works differently in the new version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ Team chat set up with 3 participants!\n",
      "ğŸ”„ Using RoundRobinGroupChat for organized collaboration\n",
      "â„¹ï¸ Each agent will contribute in turn\n"
     ]
    }
   ],
   "source": [
    "# Set up a round-robin team chat with the new API\n",
    "team = RoundRobinGroupChat([teacher, coder, reviewer], max_turns=5)\n",
    "\n",
    "print(\"ğŸ­ Team chat set up with 3 participants!\")\n",
    "print(\"ğŸ”„ Using RoundRobinGroupChat for organized collaboration\")\n",
    "print(\"â„¹ï¸ Each agent will contribute in turn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple team demonstration\nprint(\"ğŸª Simple team demo...\\n\")\n\nasync def run_simple_team_demo():\n    # Very simple task for clean demo output\n    simple_task = \"Each agent say one sentence about Python programming.\"\n    \n    result = await team.run(task=simple_task)\n    \n    # Extract clean content\n    if hasattr(result, 'messages') and result.messages:\n        responses = []\n        for msg in result.messages[-3:]:  # Show last 3 messages\n            if hasattr(msg, 'content') and hasattr(msg, 'source'):\n                responses.append(f\"{msg.source}: {msg.content}\")\n        return \"\\n\".join(responses)\n    return str(result)\n\n# Execute simple team demo\ntry:\n    team_demo_result = await run_simple_team_demo()\n    print(\"Team Responses:\")\n    print(team_demo_result)\nexcept Exception as e:\n    print(f\"Team demo encountered an issue: {e}\")\n    print(\"This is normal - team collaboration can be complex!\")\n\nprint(\"\\nğŸ‰ Simple team demo completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Basic Concept 4: Configuration Options\n",
    "\n",
    "### Understanding Key Parameters\n",
    "\n",
    "Let's explore the important configuration options that control agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ® Different Agent Configurations:\n",
      "\n",
      "ğŸ¤– Basic User Agent: Simplified proxy for human interaction\n",
      "ğŸ”’ Conservative Agent: Precise, consistent responses\n",
      "ğŸ¨ Creative Agent: Varied, imaginative responses\n",
      "â„¹ï¸ Note: The new version has simplified agent configuration\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate different agent configurations\n",
    "print(\"ğŸ® Different Agent Configurations:\\n\")\n",
    "\n",
    "# Note: In the new autogen version, UserProxyAgent has simplified parameters\n",
    "# The human input modes and code execution configs work differently\n",
    "\n",
    "# Basic UserProxyAgent (simplified in new version)\n",
    "basic_user_agent = UserProxyAgent(name=\"BasicUser\")\n",
    "\n",
    "# Multiple AssistantAgents with different personalities\n",
    "conservative_agent = AssistantAgent(\n",
    "    name=\"ConservativeAgent\",\n",
    "    system_message=\"You give precise, consistent answers with minimal creativity.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "creative_agent = AssistantAgent(\n",
    "    name=\"CreativeAgent\", \n",
    "    system_message=\"You give creative, varied responses with lots of ideas.\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Basic User Agent: Simplified proxy for human interaction\")\n",
    "print(\"ğŸ”’ Conservative Agent: Precise, consistent responses\")\n",
    "print(\"ğŸ¨ Creative Agent: Varied, imaginative responses\")\n",
    "print(\"â„¹ï¸ Note: The new version has simplified agent configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature and Creativity Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Agent personalities:\n",
      "ğŸ”’ Conservative: Consistent, predictable responses\n",
      "ğŸ¨ Creative: Varied, imaginative responses\n",
      "â„¹ï¸ Note: Temperature control is handled by the model client in the new API\n"
     ]
    }
   ],
   "source": [
    "# Create agents with different creativity levels using new API\n",
    "\n",
    "# Conservative agent (lower temperature for more deterministic responses)\n",
    "conservative_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    # Note: temperature control may be handled differently in the new API\n",
    ")\n",
    "\n",
    "conservative_agent = AssistantAgent(\n",
    "    name=\"ConservativeAgent\",\n",
    "    system_message=\"You give precise, consistent answers with minimal creativity. Be concise and factual.\",\n",
    "    model_client=conservative_model_client,\n",
    ")\n",
    "\n",
    "# Creative agent (encourage more creative responses through system message)\n",
    "creative_model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "creative_agent = AssistantAgent(\n",
    "    name=\"CreativeAgent\",\n",
    "    system_message=\"You give creative, varied responses with lots of ideas. Be imaginative and explore different perspectives.\",\n",
    "    model_client=creative_model_client,\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ Agent personalities:\")\n",
    "print(f\"ğŸ”’ Conservative: Consistent, predictable responses\")\n",
    "print(f\"ğŸ¨ Creative: Varied, imaginative responses\")\n",
    "print(\"â„¹ï¸ Note: Temperature control is handled by the model client in the new API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Basic Concept 5: Conversation Analysis\n",
    "\n",
    "### Understanding What Happened\n",
    "\n",
    "After a conversation, we can analyze the results to understand the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Run a conversation first, then we can analyze it!\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze conversation results\n",
    "def analyze_conversation(chat_result):\n",
    "    \"\"\"Simple analysis of a completed conversation\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ Conversation Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Check if we have chat history\n",
    "    if hasattr(chat_result, 'chat_history'):\n",
    "        messages = chat_result.chat_history\n",
    "        print(f\"ğŸ“¨ Total messages: {len(messages)}\")\n",
    "        \n",
    "        # Count messages by speaker\n",
    "        speakers = {}\n",
    "        for msg in messages:\n",
    "            speaker = msg.get('name', 'Unknown')\n",
    "            speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "        \n",
    "        print(\"\\nğŸ‘¥ Messages by speaker:\")\n",
    "        for speaker, count in speakers.items():\n",
    "            print(f\"  {speaker}: {count} messages\")\n",
    "        \n",
    "        # Show the conversation flow\n",
    "        print(\"\\nğŸ”„ Conversation flow:\")\n",
    "        for i, msg in enumerate(messages[-5:], 1):  # Show last 5 messages\n",
    "            speaker = msg.get('name', 'Unknown')\n",
    "            content_preview = msg.get('content', '')[:50] + \"...\"\n",
    "            print(f\"  {i}. {speaker}: {content_preview}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No detailed chat history available\")\n",
    "    \n",
    "    print(\"\\nâœ… Analysis complete!\")\n",
    "\n",
    "# Let's analyze our last conversation\n",
    "if 'chat_result' in locals():\n",
    "    analyze_conversation(chat_result)\n",
    "else:\n",
    "    print(\"ğŸ’¡ Run a conversation first, then we can analyze it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Practice Exercise: Build Your Own Simple Chat\n",
    "\n",
    "Now it's your turn! Try creating your own agents and conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Math tutoring system ready!\n",
      "Try asking the tutor to help with a math problem.\n",
      "â„¹ï¸ Use await math_tutor.run(task='your math question') to interact\n"
     ]
    }
   ],
   "source": [
    "# Your turn! Create a simple math tutor system\n",
    "\n",
    "# Create a MathTutor agent\n",
    "math_tutor = AssistantAgent(\n",
    "    name=\"MathTutor\",\n",
    "    system_message=\"\"\"You are a friendly math tutor. \n",
    "    Help students solve math problems step by step.\n",
    "    Always explain your reasoning and encourage learning.\"\"\",\n",
    "    model_client=model_client,\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ Math tutoring system ready!\")\n",
    "print(\"Try asking the tutor to help with a math problem.\")\n",
    "print(\"â„¹ï¸ Use await math_tutor.run(task='your math question') to interact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple math tutor demo\nasync def run_simple_math_demo():\n    simple_math = \"What is 2 + 2? Give a brief answer.\"\n    \n    result = await math_tutor.run(task=simple_math)\n    \n    # Extract clean content\n    if hasattr(result, 'messages') and result.messages:\n        last_message = result.messages[-1]\n        if hasattr(last_message, 'content'):\n            return last_message.content\n    return str(result)\n\n# Execute simple math demo\nmath_demo_result = await run_simple_math_demo()\nprint(\"Math Tutor Response:\", math_demo_result)\nprint(\"\\nğŸ‰ Simple math demo completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Summary: AutoGen Basic Concepts\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **ğŸ¤– Agent Types**:\n",
    "   - `UserProxyAgent`: Represents users, can execute code\n",
    "   - `AssistantAgent`: AI assistants with specialized roles\n",
    "\n",
    "2. **âš™ï¸ Key Configurations**:\n",
    "   - `llm_config`: How agents connect to language models\n",
    "   - `temperature`: Controls creativity/randomness\n",
    "   - `human_input_mode`: NEVER, ALWAYS, or TERMINATE\n",
    "   - `code_execution_config`: How and where to run code\n",
    "\n",
    "3. **ğŸ’¬ Conversation Types**:\n",
    "   - Two-agent chats: `agent1.initiate_chat(agent2)`\n",
    "   - Group chats: Multiple agents with a manager\n",
    "\n",
    "4. **ğŸ”§ Code Execution**:\n",
    "   - Agents can write and execute Python code\n",
    "   - Results are shared automatically\n",
    "   - Useful for data analysis, calculations, and testing\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- ğŸš€ Try the advanced demo notebook for complex scenarios\n",
    "- ğŸ”¨ Experiment with different agent personalities\n",
    "- ğŸŒ Explore external tool integrations\n",
    "- ğŸ“Š Build domain-specific agent teams\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding with AutoGen! ğŸ‰**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: \"No API key found\"\n",
    "```python\n",
    "# Make sure your .env file contains:\n",
    "# OPENAI_API_KEY=your_actual_api_key_here\n",
    "```\n",
    "\n",
    "### Issue 2: \"Code execution failed\"\n",
    "```python\n",
    "# Check that your work directory exists and is writable\n",
    "# Consider setting use_docker=True for better isolation\n",
    "```\n",
    "\n",
    "### Issue 3: \"Conversation doesn't end\"\n",
    "```python\n",
    "# Adjust max_round in GroupChat\n",
    "# Use human_input_mode=\"TERMINATE\" to control ending\n",
    "```\n",
    "\n",
    "### Issue 4: \"Agents aren't collaborating well\"\n",
    "```python\n",
    "# Improve system messages to clarify roles\n",
    "# Use custom speaker selection for better flow\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}