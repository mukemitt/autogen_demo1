{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– AutoGen Basic Concepts Tutorial\n",
    "\n",
    "## Welcome to AutoGen!\n",
    "\n",
    "This notebook introduces the fundamental concepts of Microsoft AutoGen - a framework for creating multi-agent conversational systems.\n",
    "\n",
    "### What You'll Learn:\n",
    "1. **Core AutoGen Concepts**: Agents, conversations, and configurations\n",
    "2. **Basic Agent Types**: UserProxyAgent and AssistantAgent\n",
    "3. **Simple Conversations**: Two-agent interactions\n",
    "4. **Code Execution**: How agents can run code\n",
    "5. **Group Chats**: Multiple agents working together\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Installation\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import autogen\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… AutoGen and dependencies imported successfully!\")\n",
    "print(f\"ğŸ“¦ AutoGen version: {autogen.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration Setup\n",
    "\n",
    "### Key Concept: LLM Configuration\n",
    "\n",
    "AutoGen agents need to know how to connect to language models. We configure this once and reuse it for all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for connecting to OpenAI\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",  # You can also use \"gpt-4\" if you have access\n",
    "        \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    }\n",
    "]\n",
    "\n",
    "# LLM configuration that will be used by our agents\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.7,  # Controls randomness (0.0 = deterministic, 1.0 = very random)\n",
    "    \"timeout\": 120,      # Maximum time to wait for a response\n",
    "}\n",
    "\n",
    "print(\"ğŸ”‘ LLM configuration ready!\")\n",
    "print(f\"ğŸ¯ Using model: {config_list[0]['model']}\")\n",
    "print(f\"ğŸŒ¡ï¸ Temperature: {llm_config['temperature']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤ Basic Concept 1: Two-Agent Conversation\n",
    "\n",
    "### UserProxyAgent vs AssistantAgent\n",
    "\n",
    "- **UserProxyAgent**: Represents the human user, can execute code\n",
    "- **AssistantAgent**: AI assistant that generates responses and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a UserProxyAgent (represents you, the user)\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    system_message=\"A human user who provides tasks and feedback.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,     # Only look at last 2 messages for code\n",
    "        \"work_dir\": \"coding\",     # Directory to run code in\n",
    "        \"use_docker\": False       # Set to True for better security\n",
    "    },\n",
    "    human_input_mode=\"NEVER\",     # NEVER, ALWAYS, or TERMINATE\n",
    ")\n",
    "\n",
    "# Create an AssistantAgent (AI assistant)\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"\"\"You are a helpful AI assistant. \n",
    "    You can help with coding, analysis, and problem-solving.\n",
    "    When you need to run code, write Python code and the user will execute it for you.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¥ Basic agents created!\")\n",
    "print(f\"ğŸ§‘ User Proxy: {user_proxy.name}\")\n",
    "print(f\"ğŸ¤– Assistant: {assistant.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Have Our First Conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a simple conversation\n",
    "print(\"ğŸ—£ï¸ Starting a basic two-agent conversation...\\n\")\n",
    "\n",
    "# The user proxy initiates the conversation\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Hello! Can you help me calculate the fibonacci sequence up to the 10th number? \n",
    "    Please write Python code to do this and explain how it works.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Conversation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Basic Concept 2: Code Execution\n",
    "\n",
    "### How AutoGen Handles Code\n",
    "\n",
    "1. Assistant writes code in markdown code blocks\n",
    "2. UserProxy detects the code and executes it\n",
    "3. Results are shared back with the assistant\n",
    "4. Conversation continues based on results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a more complex coding task\n",
    "print(\"ğŸ”¢ Testing code execution capabilities...\\n\")\n",
    "\n",
    "coding_task = \"\"\"\n",
    "I need help with data analysis. Can you:\n",
    "1. Create a small dataset of student grades\n",
    "2. Calculate the average, median, and standard deviation\n",
    "3. Create a simple visualization\n",
    "\n",
    "Please write and run the Python code to accomplish this.\n",
    "\"\"\"\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=coding_task\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Data analysis task completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘¥ Basic Concept 3: Group Chat (Multiple Agents)\n",
    "\n",
    "### Beyond Two Agents\n",
    "\n",
    "Group chats allow multiple agents to collaborate on complex tasks. Each agent can have specialized roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents for a group chat\n",
    "\n",
    "# Teacher agent - explains concepts\n",
    "teacher = autogen.AssistantAgent(\n",
    "    name=\"Teacher\",\n",
    "    system_message=\"\"\"You are a patient teacher who explains programming concepts clearly.\n",
    "    Focus on education and helping students understand the 'why' behind solutions.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Coder agent - writes code\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=\"\"\"You are an expert programmer who writes clean, efficient code.\n",
    "    Focus on practical implementation and best practices.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Reviewer agent - checks and improves code\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"Reviewer\",\n",
    "    system_message=\"\"\"You are a code reviewer who focuses on quality, security, and optimization.\n",
    "    Point out potential issues and suggest improvements.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¨â€ğŸ« Specialized agents created:\")\n",
    "print(f\"ğŸ“š Teacher: {teacher.name}\")\n",
    "print(f\"ğŸ’» Coder: {coder.name}\")\n",
    "print(f\"ğŸ” Reviewer: {reviewer.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the group chat\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, teacher, coder, reviewer],\n",
    "    messages=[],\n",
    "    max_round=12,  # Maximum number of back-and-forth exchanges\n",
    "    speaker_selection_method=\"round_robin\",  # or \"auto\" for automatic selection\n",
    ")\n",
    "\n",
    "# Create a manager to coordinate the group chat\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You coordinate the conversation between team members.\"\n",
    ")\n",
    "\n",
    "print(\"ğŸ­ Group chat set up with 4 participants!\")\n",
    "print(f\"ğŸ”„ Max rounds: {groupchat.max_round}\")\n",
    "print(f\"ğŸ¯ Speaker selection: {groupchat.speaker_selection_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a group discussion\n",
    "print(\"ğŸª Starting group chat discussion...\\n\")\n",
    "\n",
    "group_task = \"\"\"\n",
    "Our team needs to create a simple calculator program that can:\n",
    "1. Add, subtract, multiply, and divide two numbers\n",
    "2. Handle division by zero errors\n",
    "3. Have a user-friendly interface\n",
    "\n",
    "Teacher: Please explain the concept first\n",
    "Coder: Then implement the solution\n",
    "Reviewer: Finally review and suggest improvements\n",
    "\n",
    "Let's work together on this!\n",
    "\"\"\"\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=group_task\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ Group collaboration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Basic Concept 4: Configuration Options\n",
    "\n",
    "### Understanding Key Parameters\n",
    "\n",
    "Let's explore the important configuration options that control agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different human input modes\n",
    "print(\"ğŸ® Different Human Input Modes:\\n\")\n",
    "\n",
    "# Mode 1: NEVER (fully automated)\n",
    "auto_agent = autogen.UserProxyAgent(\n",
    "    name=\"AutoAgent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"work_dir\": \"auto_coding\"}\n",
    ")\n",
    "\n",
    "# Mode 2: ALWAYS (requires human input for every response)\n",
    "interactive_agent = autogen.UserProxyAgent(\n",
    "    name=\"InteractiveAgent\", \n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    code_execution_config={\"work_dir\": \"interactive_coding\"}\n",
    ")\n",
    "\n",
    "# Mode 3: TERMINATE (human can choose when to end)\n",
    "selective_agent = autogen.UserProxyAgent(\n",
    "    name=\"SelectiveAgent\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    code_execution_config={\"work_dir\": \"selective_coding\"}\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– NEVER mode: Fully automated, no human intervention\")\n",
    "print(\"ğŸ‘¤ ALWAYS mode: Human input required for every step\")\n",
    "print(\"ğŸ›‘ TERMINATE mode: Human can choose when to stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature and Creativity Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with different creativity levels\n",
    "\n",
    "# Conservative agent (low temperature)\n",
    "conservative_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.1,  # Very deterministic\n",
    "}\n",
    "\n",
    "conservative_agent = autogen.AssistantAgent(\n",
    "    name=\"ConservativeAgent\",\n",
    "    system_message=\"You give precise, consistent answers with minimal creativity.\",\n",
    "    llm_config=conservative_config,\n",
    ")\n",
    "\n",
    "# Creative agent (high temperature)\n",
    "creative_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.9,  # Very creative\n",
    "}\n",
    "\n",
    "creative_agent = autogen.AssistantAgent(\n",
    "    name=\"CreativeAgent\",\n",
    "    system_message=\"You give creative, varied responses with lots of ideas.\",\n",
    "    llm_config=creative_config,\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ Agent personalities:\")\n",
    "print(f\"ğŸ”’ Conservative (temp=0.1): Consistent, predictable responses\")\n",
    "print(f\"ğŸ¨ Creative (temp=0.9): Varied, imaginative responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Basic Concept 5: Conversation Analysis\n",
    "\n",
    "### Understanding What Happened\n",
    "\n",
    "After a conversation, we can analyze the results to understand the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze conversation results\n",
    "def analyze_conversation(chat_result):\n",
    "    \"\"\"Simple analysis of a completed conversation\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ Conversation Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Check if we have chat history\n",
    "    if hasattr(chat_result, 'chat_history'):\n",
    "        messages = chat_result.chat_history\n",
    "        print(f\"ğŸ“¨ Total messages: {len(messages)}\")\n",
    "        \n",
    "        # Count messages by speaker\n",
    "        speakers = {}\n",
    "        for msg in messages:\n",
    "            speaker = msg.get('name', 'Unknown')\n",
    "            speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "        \n",
    "        print(\"\\nğŸ‘¥ Messages by speaker:\")\n",
    "        for speaker, count in speakers.items():\n",
    "            print(f\"  {speaker}: {count} messages\")\n",
    "        \n",
    "        # Show the conversation flow\n",
    "        print(\"\\nğŸ”„ Conversation flow:\")\n",
    "        for i, msg in enumerate(messages[-5:], 1):  # Show last 5 messages\n",
    "            speaker = msg.get('name', 'Unknown')\n",
    "            content_preview = msg.get('content', '')[:50] + \"...\"\n",
    "            print(f\"  {i}. {speaker}: {content_preview}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No detailed chat history available\")\n",
    "    \n",
    "    print(\"\\nâœ… Analysis complete!\")\n",
    "\n",
    "# Let's analyze our last conversation\n",
    "if 'chat_result' in locals():\n",
    "    analyze_conversation(chat_result)\n",
    "else:\n",
    "    print(\"ğŸ’¡ Run a conversation first, then we can analyze it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Practice Exercise: Build Your Own Simple Chat\n",
    "\n",
    "Now it's your turn! Try creating your own agents and conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn! Create a simple math tutor system\n",
    "\n",
    "# TODO: Create a MathTutor agent\n",
    "math_tutor = autogen.AssistantAgent(\n",
    "    name=\"MathTutor\",\n",
    "    system_message=\"\"\"You are a friendly math tutor. \n",
    "    Help students solve math problems step by step.\n",
    "    Always explain your reasoning and encourage learning.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# TODO: Create a Student agent (UserProxy)\n",
    "student = autogen.UserProxyAgent(\n",
    "    name=\"Student\",\n",
    "    system_message=\"A student learning mathematics.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"work_dir\": \"math_practice\"}\n",
    ")\n",
    "\n",
    "print(\"ğŸ“ Math tutoring system ready!\")\n",
    "print(\"Try asking the tutor to help with a math problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice conversation\n",
    "math_problem = \"\"\"\n",
    "Hi! I need help solving this quadratic equation: xÂ² + 5x + 6 = 0\n",
    "\n",
    "Can you:\n",
    "1. Show me how to solve it step by step\n",
    "2. Verify the answer by substituting back\n",
    "3. Explain what the solutions mean graphically\n",
    "\"\"\"\n",
    "\n",
    "practice_result = student.initiate_chat(\n",
    "    math_tutor,\n",
    "    message=math_problem\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ Math tutoring session completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Summary: AutoGen Basic Concepts\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **ğŸ¤– Agent Types**:\n",
    "   - `UserProxyAgent`: Represents users, can execute code\n",
    "   - `AssistantAgent`: AI assistants with specialized roles\n",
    "\n",
    "2. **âš™ï¸ Key Configurations**:\n",
    "   - `llm_config`: How agents connect to language models\n",
    "   - `temperature`: Controls creativity/randomness\n",
    "   - `human_input_mode`: NEVER, ALWAYS, or TERMINATE\n",
    "   - `code_execution_config`: How and where to run code\n",
    "\n",
    "3. **ğŸ’¬ Conversation Types**:\n",
    "   - Two-agent chats: `agent1.initiate_chat(agent2)`\n",
    "   - Group chats: Multiple agents with a manager\n",
    "\n",
    "4. **ğŸ”§ Code Execution**:\n",
    "   - Agents can write and execute Python code\n",
    "   - Results are shared automatically\n",
    "   - Useful for data analysis, calculations, and testing\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- ğŸš€ Try the advanced demo notebook for complex scenarios\n",
    "- ğŸ”¨ Experiment with different agent personalities\n",
    "- ğŸŒ Explore external tool integrations\n",
    "- ğŸ“Š Build domain-specific agent teams\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding with AutoGen! ğŸ‰**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Troubleshooting Common Issues\n",
    "\n",
    "### Issue 1: \"No API key found\"\n",
    "```python\n",
    "# Make sure your .env file contains:\n",
    "# OPENAI_API_KEY=your_actual_api_key_here\n",
    "```\n",
    "\n",
    "### Issue 2: \"Code execution failed\"\n",
    "```python\n",
    "# Check that your work directory exists and is writable\n",
    "# Consider setting use_docker=True for better isolation\n",
    "```\n",
    "\n",
    "### Issue 3: \"Conversation doesn't end\"\n",
    "```python\n",
    "# Adjust max_round in GroupChat\n",
    "# Use human_input_mode=\"TERMINATE\" to control ending\n",
    "```\n",
    "\n",
    "### Issue 4: \"Agents aren't collaborating well\"\n",
    "```python\n",
    "# Improve system messages to clarify roles\n",
    "# Use custom speaker selection for better flow\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}